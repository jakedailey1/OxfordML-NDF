{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "#custom libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file_format(filename_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, value = reader.read(filename_queue)\n",
    "\n",
    "    record_defaults = [tf.constant([], dtype=tf.float32), tf.constant([], dtype=tf.int32)]\n",
    "    _, col2 = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "#     col2 = tf.string_to_number(col2, out_type=tf.int32)\n",
    "    \n",
    "    example = tf.stack([col2])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_pipeline(filenames, batch_size = 3, num_epochs = None, evaluation = False):   \n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        filenames, num_epochs=num_epochs, shuffle=False)\n",
    "\n",
    "    example = read_file_format(filename_queue)\n",
    "        \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _activation_summary(x):\n",
    "    tensor_name = x.name\n",
    "    tensor_name = tensor_name.replace(':', '_')\n",
    "    tensor_name = tensor_name.replace('(', '_')\n",
    "    tensor_name = tensor_name.replace(')', '_')\n",
    "    tensor_name = tensor_name.replace(' ', '_')\n",
    "\n",
    "    tf.summary.histogram(tensor_name + '/activations', x)\n",
    "    tf.summary.scalar(tensor_name + '/sparsity', tf.nn.zero_fraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to factor so a block can replicate cells \n",
    "class LSTM_Block:\n",
    "    \n",
    "    def __init__(self, activation=tf.tanh, forget_bias=1.0, num_cells=1):\n",
    "        self.block_num = block_num\n",
    "        self.forget_bias = forget_bias\n",
    "        self.activation = activation\n",
    "        self.num_cells = num_cells\n",
    "        self.state = tf.zeroes([batch_size, tf.shape(i_tensor)])\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        for c in range(num_cells):\n",
    "            with tf.variable_scope('input{0}.{1}'.format(block_num, c)) as scope:\n",
    "                i_tensor = tf.concat([input_tensor, self.cell_value])\n",
    "\n",
    "                weights = tf.Variable(tf.random_normal(tf.shape(i_tensor)), name='weights', trainable=True)\n",
    "                biases = tf.Variable(tf.random_normal(tf.shape(i_tensor)[1]), name='bias', trainable=True)\n",
    "\n",
    "                lin_i = tf.matmul(i_tensor, weights) + biases\n",
    "                _activation_summary(lin_i)\n",
    "\n",
    "                gate_i = tf.sigmoid(lin_i)\n",
    "                _activation_summary(gate_i)\n",
    "\n",
    "            with tf.variable_scope('forget{0}.{1}'.format(block_num, c)) as scope:\n",
    "                f_tensor = tf.concat([input_tensor, self.cell_value])\n",
    "\n",
    "                weights = tf.Variable(tf.random_normal(tf.shape(f_tensor)), name='weights', trainable=True)\n",
    "                biases = tf.Variable(tf.random_normal(tf.shape(f_tensor)[1]), name='bias', trainable=True)\n",
    "\n",
    "                lin_f = tf.matmul(f_tensor, weights) + biases\n",
    "                _activation_summary(lin_f)\n",
    "\n",
    "                gate_f = tf.sigmoid(lin_f)\n",
    "                _activation_summary(gate_f)\n",
    "\n",
    "            with tf.variable_scope('cell{0}.{1}'.format(block_num, c)) as scope:\n",
    "                weights = tf.Variable(tf.random_normal(tf.shape(input_tensor)), name='weights', trainable=True)\n",
    "                biases = tf.Variable(tf.random_normal(tf.shape(input_tensor)[1]), name='bias', trainable=True)\n",
    "\n",
    "                lin_state = tf.matmul(input_tensor, weights) + biases\n",
    "                _activation_summary(lin_c)\n",
    "\n",
    "                input_state = tf.matmul(gate_i, activation(lin_state))\n",
    "                past_state = tf.matmul(gate_f, self.state)\n",
    "                new_state = input_state + past_state\n",
    "                _activation_summary(new_state)\n",
    "\n",
    "                self.state = new_state\n",
    "\n",
    "            with tf.variable_scope('output{0}.{1}'.format(block_num, c)) as scope:\n",
    "                o_tensor = tf.concat([input_tensor, self.cell_value])\n",
    "\n",
    "                weights = tf.Variable(tf.random_normal(tf.shape(o_tensor)), name='weights', trainable=True)\n",
    "                biases = tf.Variable(tf.random_normal(tf.shape(o_tensor)[1]), name='bias', trainable=True)\n",
    "\n",
    "                lin_o = tf.matmul(o_tensor, weights) + biases\n",
    "                _activation_summary(lin_o)\n",
    "\n",
    "                gate_o = tf.sigmoid(lin_o)\n",
    "                _activation_summary(gate_o)\n",
    "\n",
    "            with tf.variable_scope('hidden{0}.{1}'.format(block_num, c)) as scope:\n",
    "                hidden = tf.matmul(gate_o, activation(self.cell_value))\n",
    "                _activation_summary(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(X):\n",
    "    block1 = lstm_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(logits, labels):\n",
    "    NLLCriterion = -tf.reduce_mean(tf.reduce_sum(tf.multiply(labels, tf.log(logits + 1e-10)), axis=1))\n",
    "\n",
    "    tf.add_to_collection('losses', NLLCriterion)\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"{0}/{1}\".format(data_path, train_file), nrows=10, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global data_path\n",
    "data_path = \"data\"\n",
    "\n",
    "global vocab_file\n",
    "vocab_file = \"vocab1.csv\"\n",
    "\n",
    "global train_file\n",
    "train_file = \"train1.csv\"\n",
    "\n",
    "global batch_size\n",
    "batch_size = 16\n",
    "\n",
    "global seq_length\n",
    "seq_length = 16\n",
    "\n",
    "global num_epochs\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    y_ = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "    y_hat = make_prediction(x)\n",
    "\n",
    "    #need appropriate loss function\n",
    "    loss = calculate_loss(y_hat, y_)\n",
    "\n",
    "    #need to figure out gradient clipping in TF\n",
    "    #need trunc. backprop through time\n",
    "    train_op = train(loss, global_step=global_step)\n",
    "    step = 0\n",
    "\n",
    "    accuracy = evaluate_accuracy(y_hat, y_)\n",
    "\n",
    "    example_feed = input_pipeline([\"{0}/{1}\".format(data_path, train_file)],\n",
    "                                  batch_size = batch_size, num_epochs = num_epochs)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Start populating the filename queue.\n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()  \n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        \n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "#             try:\n",
    "            start_time = time.time()                \n",
    "\n",
    "            example_batch = sess.run(example_feed)\n",
    "        \n",
    "            duration = time.time() - start_time\n",
    "            step += 1\n",
    "\n",
    "            except (tf.errors.OutOfRangeError, tf.errors.InvalidArgumentError) as e:\n",
    "           \n",
    "                print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "                # When done, ask the threads to stop.\n",
    "                coord.request_stop()\n",
    "\n",
    "        \n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global block_num\n",
    "block_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = pd.read_csv(\"{0}/{1}\".format(data_path, vocab_file),\n",
    "                    header=None)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
